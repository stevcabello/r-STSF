{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nestor Cabello, Elham Naghizade, Jianzhong Qi, Lars Kulik\n",
    "\n",
    "# Cabello N, Naghizade E, Qi J, Kulik L (2021) Fast, Accurate and Interpretable Time Series Classification \n",
    "# Through Randomization.\n",
    "\n",
    "\n",
    "from rSTSF_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 85 benchmark datasets from the UCR repository (http://timeseriesclassification.com)\n",
    "# dset_names = [\"Adiac\",\"ArrowHead\",\"Beef\",\"BeetleFly\",\"BirdChicken\",\"Car\",\"CBF\",\n",
    "#               \"ChlorineConcentration\",\"CinCECGTorso\",\"Coffee\",\"Computers\",\"CricketX\",\n",
    "#               \"CricketY\",\"CricketZ\",\"DiatomSizeReduction\",\n",
    "#               \"DistalPhalanxOutlineAgeGroup\",\"DistalPhalanxOutlineCorrect\",\n",
    "#               \"DistalPhalanxTW\",\"Earthquakes\",\"ECG200\",\"ECG5000\",\"ECGFiveDays\",\"ElectricDevices\",\n",
    "#               \"FaceAll\",\"FaceFour\",\"FacesUCR\",\"FiftyWords\",\"Fish\",\"FordA\",\"FordB\",\n",
    "#               \"GunPoint\",\"Ham\",\"HandOutlines\",\n",
    "#               \"Haptics\",\"Herring\",\"InlineSkate\",\n",
    "#               \"InsectWingbeatSound\",\"ItalyPowerDemand\",\"LargeKitchenAppliances\",\n",
    "#               \"Lightning2\",\"Lightning7\",\"Mallat\",\"Meat\",\"MedicalImages\",\n",
    "#               \"MiddlePhalanxOutlineAgeGroup\",\"MiddlePhalanxOutlineCorrect\",\"MiddlePhalanxTW\",\n",
    "#               \"MoteStrain\",\"NonInvasiveFetalECGThorax1\",\"NonInvasiveFetalECGThorax2\",\"OliveOil\",\"OSULeaf\",\n",
    "#               \"PhalangesOutlinesCorrect\",\n",
    "#               \"Phoneme\",\"Plane\",\n",
    "#               \"ProximalPhalanxOutlineAgeGroup\",\"ProximalPhalanxOutlineCorrect\",\"ProximalPhalanxTW\",\n",
    "#               \"RefrigerationDevices\",\"ScreenType\",\n",
    "#               \"ShapeletSim\",\"ShapesAll\",\"SmallKitchenAppliances\",\n",
    "#               \"SonyAIBORobotSurface1\",\"SonyAIBORobotSurface2\",\"StarLightCurves\",\n",
    "#               \"Strawberry\",\"SwedishLeaf\",\"Symbols\",\"SyntheticControl\",\n",
    "#               \"ToeSegmentation1\",\"ToeSegmentation2\",\"Trace\",\"TwoLeadECG\",\"TwoPatterns\",\n",
    "#               \"UWaveGestureLibraryAll\",\"UWaveGestureLibraryX\",\"UWaveGestureLibraryY\",\"UWaveGestureLibraryZ\",\n",
    "#               \"Wafer\",\"Wine\",\"WordSynonyms\",\"Worms\",\"WormsTwoClass\",\"Yoga\"]\n",
    "\n",
    "## 43 additional datasets from the UCR repository (http://timeseriesclassification.com)\n",
    "# dset_names = [\"ACSF1\", \"AllGestureWiimoteX\",\"AllGestureWiimoteY\",\"AllGestureWiimoteZ\",\n",
    "#               \"BME\",\"Chinatown\",\"Crop\", \"DodgerLoopDay\",\"DodgerLoopGame\",\"DodgerLoopWeekend\",\n",
    "#               \"EOGHorizontalSignal\",\"EOGVerticalSignal\",\"EthanolLevel\",\"FreezerRegularTrain\",\"FreezerSmallTrain\",\n",
    "#               \"Fungi\", \"GestureMidAirD1\", \"GestureMidAirD2\", \"GestureMidAirD3\", \"GesturePebbleZ1\", \"GesturePebbleZ2\",\n",
    "#               \"GunPointAgeSpan\",\"GunPointMaleVersusFemale\",\"GunPointOldVersusYoung\",\n",
    "#               \"HouseTwenty\",\"InsectEPGRegularTrain\",\"InsectEPGSmallTrain\",\n",
    "#               \"MelbournePedestrian\",\"MixedShapesRegularTrain\",\"MixedShapesSmallTrain\",\n",
    "#               \"PLAID\",\"PickupGestureWiimoteZ\",\"PigAirwayPressure\",\"PigArtPressure\",\n",
    "#               \"PigCVP\",\"PowerCons\",\"Rock\",\"SemgHandGenderCh2\",\"SemgHandMovementCh2\",\"SemgHandSubjectCh2\",\n",
    "#               \"ShakeGestureWiimoteZ\",\"SmoothSubspace\",\"UMD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  ItalyPowerDemand\n",
      "run  1\n",
      "training time:  1.581384989000071\n",
      "testing time:  0.6833054840026307\n",
      "accuracy:  0.9727891156462585\n",
      "run  2\n",
      "training time:  1.814018474000477\n",
      "testing time:  0.608274900001561\n",
      "accuracy:  0.9737609329446064\n",
      "run  3\n",
      "training time:  1.5461253920002491\n",
      "testing time:  1.705918808998831\n",
      "accuracy:  0.9718172983479106\n",
      "run  4\n",
      "training time:  1.5608163290016819\n",
      "testing time:  0.6141648250013532\n",
      "accuracy:  0.9737609329446064\n",
      "run  5\n",
      "training time:  1.5199255789993913\n",
      "testing time:  0.6116699260019232\n",
      "accuracy:  0.9737609329446064\n",
      "run  6\n",
      "training time:  1.6070880990009755\n",
      "testing time:  1.0241273009996803\n",
      "accuracy:  0.9737609329446064\n",
      "run  7\n",
      "training time:  3.4471930920008163\n",
      "testing time:  1.0309765969977889\n",
      "accuracy:  0.9737609329446064\n",
      "run  8\n",
      "training time:  2.059693645001971\n",
      "testing time:  1.4476360280023073\n",
      "accuracy:  0.9727891156462585\n",
      "run  9\n",
      "training time:  2.4981720299983863\n",
      "testing time:  0.7756279839995841\n",
      "accuracy:  0.9718172983479106\n",
      "run  10\n",
      "training time:  2.191355069997371\n",
      "testing time:  0.7305190780025441\n",
      "accuracy:  0.9737609329446064\n",
      "avg accuracy for 10 runs:  0.9731778425655978\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dset_names = [\"ItalyPowerDemand\"]\n",
    "# dset_names = [\"ItalyPowerDemand\",\"LargeKitchenAppliances\",\"SonyAIBORobotSurface2\",\"ECG200\"]\n",
    "\n",
    "agg_fns = [np.mean, np.std, np.polyfit, np.median, np.min, np.max, iqr, np.percentile, np.quantile]\n",
    "# np.percentile and np.quantile are just used as identifiers for \n",
    "# count mean-crossings and count of values above mean statistics. See function getIntervalFeature(...)\n",
    "\n",
    "nruns = 10\n",
    "repr_types = [1,2,3,4] # 1: Raw series, 2: Periodogram, 3: First-order Difference, 4: Autoregressive\n",
    "d = 50 # Number of sets of candidate discriminatory interval features to compute\n",
    "r = 500 # Number of trees\n",
    "\n",
    "accuracies = np.zeros((len(dset_names),nruns))\n",
    "training_times = []\n",
    "testing_times = []\n",
    "\n",
    "cont_dsets = 0\n",
    "for dset_name in dset_names:\n",
    "    print(\"Dataset: \", dset_name)\n",
    "\n",
    "    X_train_ori, y_train_ori, X_test, y_test = getTrainTestSets(dset_name)\n",
    "    \n",
    "    inner_training_time = []\n",
    "    inner_testing_time = []\n",
    "    \n",
    "    for nrun in range(nruns):\n",
    "        print('run ',str(nrun+1))\n",
    "        timeA = time.perf_counter()\n",
    "        \n",
    "        #For cases of unbalanced datasets --> oversampling\n",
    "        X_train, per_X_train, diff_X_train, ar_X_train, y_train = dataAugmented(X_train_ori,y_train_ori)\n",
    "\n",
    "        \n",
    "        # For the extraction of candidate interval features we use the FisherScore feature ranking metric. \n",
    "        # For such metric, all features must z-normalized.\n",
    "        X_train_norm = zscore(X_train, axis=0, ddof=1)\n",
    "        X_train_norm[np.isnan(X_train_norm)] = 0 # In case of Nan values set them to zero\n",
    "        per_X_train_norm = getPeriodogramRepr(X_train_norm)\n",
    "        diff_X_train_norm = np.diff(X_train_norm)\n",
    "\n",
    "        ar_X_train_norm = ar_coefs(X_train_norm)\n",
    "        ar_X_train_norm[np.isnan(ar_X_train_norm)] = 0 # In case of Nan values set them to zero\n",
    "\n",
    "        all_X_train_T = np.zeros((X_train.shape[0],1))\n",
    "        all_candidate_agg_feats = []\n",
    "\n",
    "\n",
    "        for t in range(d): # Compute d sets of candidate discriminatory interval features \n",
    "            candidate_agg_feats,X_train_T = getAllCandidateAggFeats(X_train, y_train, agg_fns, repr_types, \n",
    "                                                             per_X_train, diff_X_train, ar_X_train,\n",
    "                                                             X_train_norm, per_X_train_norm, diff_X_train_norm,\n",
    "                                                             ar_X_train_norm)\n",
    "            \n",
    "            # Merge each computed interval-based representation\n",
    "            all_X_train_T = np.hstack((all_X_train_T,X_train_T)) \n",
    "            all_candidate_agg_feats.extend(candidate_agg_feats)\n",
    "        \n",
    "        all_X_train_T = all_X_train_T[:,1:]\n",
    "\n",
    "        clf = ExtraTreesClassifier(n_estimators=r,criterion='entropy',class_weight='balanced',max_features='sqrt')\n",
    "        clf.fit(all_X_train_T, y_train) # Train the ensemble of ET classifiers\n",
    "\n",
    "        current_training_time = time.perf_counter()-timeA\n",
    "        inner_training_time.append(current_training_time)\n",
    "        print(\"training time: \", current_training_time)\n",
    "\n",
    "        timeA = time.perf_counter()\n",
    "        \n",
    "        per_X_test = getPeriodogramRepr(X_test)\n",
    "        diff_X_test = np.diff(X_test)\n",
    "        ar_X_test = ar_coefs(X_test)\n",
    "        ar_X_test[np.isnan(ar_X_test)] = 0\n",
    "\n",
    "        # The testing set has to be transformed into an interval-based representation\n",
    "        # use only the relevant interval as according to the training process (i.e., tree nodes)\n",
    "        relevant_caf_idx = [] \n",
    "        for dt_tree in clf.estimators_:\n",
    "            caf_idx_to_train = dt_tree.tree_.feature\n",
    "            relevant_caf_idx.extend(caf_idx_to_train[caf_idx_to_train>=0])\n",
    "        relevant_caf_idx = np.unique(relevant_caf_idx)\n",
    "        \n",
    "        X_test_T = getIntervalBasedTransform(X_test, per_X_test, diff_X_test, ar_X_test, all_candidate_agg_feats, relevant_caf_idx)\n",
    "        y_pred = clf.predict(X_test_T)\n",
    "\n",
    "        current_testing_time = time.perf_counter()-timeA\n",
    "        inner_testing_time.append(current_testing_time)\n",
    "        print(\"testing time: \", current_testing_time)\n",
    "\n",
    "        accu = np.sum(y_pred==y_test)/len(y_test)\n",
    "        print('accuracy: ', accu)\n",
    "        accuracies[cont_dsets,nrun] = accu\n",
    "\n",
    "    avg_accuracy_this_dataset = np.mean(accuracies[cont_dsets,:])\n",
    "    print('avg accuracy for ' + str(nruns) + ' runs: ' , avg_accuracy_this_dataset)\n",
    "    \n",
    "    training_times.append(np.mean(inner_training_time))\n",
    "    testing_times.append(np.mean(inner_testing_time))\n",
    "\n",
    "    cont_dsets+=1\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "## comment/uncomment the lines below according to the number of runs\n",
    "columns = {'Dataset':dset_names,\n",
    "           'run1':accuracies[:,0],\n",
    "               'run2':accuracies[:,1],\n",
    "               'run3':accuracies[:,2],\n",
    "               'run4':accuracies[:,3],\n",
    "               'run5':accuracies[:,4],\n",
    "               'run6':accuracies[:,5],\n",
    "               'run7':accuracies[:,6],\n",
    "               'run8':accuracies[:,7],\n",
    "               'run9':accuracies[:,8],\n",
    "               'run10':accuracies[:,9],\n",
    "           'avgAccu':np.mean(accuracies,axis=1),\n",
    "           'avgTrainTime':np.array(training_times),'avgTestTime':np.array(testing_times)}\n",
    "dfResults = pd.DataFrame(columns)\n",
    "dfResults = dfResults[['Dataset',\n",
    "                       'run1',\n",
    "                           'run2',\n",
    "                           'run3',\n",
    "                           'run4',\n",
    "                           'run5',\n",
    "                           'run6',\n",
    "                           'run7',\n",
    "                           'run8',\n",
    "                           'run9',\n",
    "                           'run10',\n",
    "                       'avgAccu','avgTrainTime','avgTestTime'\n",
    "                      ]]\n",
    "    \n",
    "\n",
    "dfResults.to_csv(\"output/r-STSF_experiment_run_at_\" + time.strftime(\"%d-%m-%Y %H%M%S\") + \".csv\",encoding='utf-8' ,index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
